{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thomasdevasia/deep-image-prior/blob/master/SAR_Despeckling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NqnrtFZmwJs",
        "outputId": "92856753-fcc4-47fd-c9ab-ef991123af06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-image-prior'...\n",
            "remote: Enumerating objects: 412, done.\u001b[K\n",
            "remote: Counting objects: 100% (123/123), done.\u001b[K\n",
            "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "remote: Total 412 (delta 58), reused 94 (delta 44), pack-reused 289\u001b[K\n",
            "Receiving objects: 100% (412/412), 126.42 MiB | 50.12 MiB/s, done.\n",
            "Resolving deltas: 100% (213/213), done.\n",
            "/content/deep-image-prior\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/thomasdevasia/deep-image-prior\n",
        "# !mv deep-image-prior/* ./\n",
        "%cd deep-image-prior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a51yIFT9m-oi"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "#os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
        "\n",
        "import numpy as np\n",
        "from models import *\n",
        "\n",
        "import torch\n",
        "import torch.optim\n",
        "\n",
        "# from skimage.measure import compare_psnr\n",
        "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
        "from utils.denoising_utils import *\n",
        "\n",
        "import scipy.io as sio\n",
        "\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark =True\n",
        "dtype = torch.cuda.FloatTensor\n",
        "\n",
        "imsize =-1\n",
        "\n",
        "# plotting image inside closure\n",
        "PLOT = True\n",
        "\n",
        "sigma = 25\n",
        "sigma_ = sigma/255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWYvpR5anwoL"
      },
      "outputs": [],
      "source": [
        "# png SAR image\n",
        "fnamep = 'data/denoising/SAR3.png'\n",
        "# .mat SAR images\n",
        "# fname = 'data/denoising/CL7.mat'\n",
        "fname = 'data/denoising/CL8.mat'\n",
        "# fname = 'data/denoising/CL9.mat'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rns52qtC6C2W"
      },
      "source": [
        "# Load and prepare Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_WmPhGR4lfz"
      },
      "outputs": [],
      "source": [
        "# reading mat files\n",
        "test = sio.loadmat(fname)\n",
        "intImage = test['x2']\n",
        "temp = pil_to_np(intImage)\n",
        "img_pil = np_to_pil(temp)\n",
        "img_pil = crop_image(img_pil, d=32)\n",
        "img_np = 255*pil_to_np(img_pil)\n",
        "\n",
        "# normalizing image\n",
        "val_min = img_np.min()\n",
        "val_range = img_np.max() - val_min\n",
        "img_np = (img_np - val_min) / val_range \n",
        "\n",
        "# img_np = pil_to_np(img_pil)\n",
        "# img_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLHpKM8Kq6gG",
        "outputId": "cd99111f-ca19-4b9a-c628-40fe380e1fc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 672, 672)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "img_np.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNFd8paesUYn"
      },
      "outputs": [],
      "source": [
        "# img_pil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vH2TE-IOpe1E"
      },
      "outputs": [],
      "source": [
        "# img_noisy_pil = crop_image(get_image(fname, imsize)[0], d=32)\n",
        "# img_noisy_np = pil_to_np(img_noisy_pil)\n",
        "\n",
        "# img_pil = img_noisy_pil\n",
        "# img_np = img_noisy_np\n",
        "\n",
        "# plot_image_grid([img_np], 4, 5);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSUzmLAHMlXQ"
      },
      "outputs": [],
      "source": [
        "# im = crop_image(get_image(fname, imsize)[0], d=128)\n",
        "# im.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLTFtawRq6RL"
      },
      "outputs": [],
      "source": [
        "# # reading png files\n",
        "# # img_pil = get_image(fname, imsize)[0]\n",
        "# img_pil = crop_image(get_image(fnamep, imsize)[0], d=32)\n",
        "# # converting to numpy\n",
        "# img_np = pil_to_np(img_pil)\n",
        "# # img_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prwA1lGHAcB3"
      },
      "outputs": [],
      "source": [
        "# # # adding speckle noise\n",
        "# def get_noisy_img(img_np, sigma):\n",
        "#   \"\"\"Adds noise to an image.\n",
        "    \n",
        "#   Args: \n",
        "#       img_np: image, np.array with values from 0 to 1\n",
        "#       sigma: std of the noise\n",
        "#   \"\"\"\n",
        "\n",
        "#   np.random.seed(42)\n",
        "\n",
        "#   noise = np.random.normal(loc=1, scale=sigma_, size=img_np.shape)\n",
        "\n",
        "#   # multiplicative noise for speckle noise\n",
        "#   # imgNoise = img_np + (img_np * noise)\n",
        "#   imgNoise = np.log(img_np * noise)\n",
        "\n",
        "#   img_noisy_np = np.clip(abs(imgNoise), 0, 1).astype(np.float32)\n",
        "    \n",
        "#   img_noisy_pil = np_to_pil(img_noisy_np)\n",
        "\n",
        "#   return img_noisy_pil, img_noisy_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrEixrIHVOov"
      },
      "outputs": [],
      "source": [
        "# correct way\n",
        "# from sklearn import preprocessing\n",
        "def generateAddSpeckle(img_np, L):\n",
        "\n",
        "    '''\n",
        "\n",
        "    Creates multiplicative speckled image with number of looks L. L increases lower noise effect, L is lower noise is strong. \n",
        "\n",
        "    '''\n",
        "\n",
        "    sum_ = 0\n",
        "\n",
        "    for i in range(L):\n",
        "\n",
        "        seq1 = np.random.randn(img_np.shape[1], img_np.shape[2])\n",
        "\n",
        "        seq2 = np.random.randn(img_np.shape[1], img_np.shape[2])\n",
        "\n",
        "        temp = np.multiply(seq1, seq1) + np.multiply(seq2, seq2)\n",
        "\n",
        "        sum_ = sum_ + temp/2\n",
        "\n",
        "        #print(i)\n",
        "\n",
        "    speckle_ = np.multiply(sum_,1/L)\n",
        "\n",
        "    img_noisy_np = np.multiply(img_np, speckle_)\n",
        "    img_noisy_np = np.clip(img_noisy_np, 0, 1).astype(np.float32)\n",
        "    img_noisy_np = np.log(img_noisy_np)\n",
        "    img_noisy_np[img_noisy_np==-np.inf] = 0\n",
        "\n",
        "    # img_noisy_np = np.log(img_noisy_np)\n",
        "    \n",
        "    # norm = np.linalg.norm(img_noisy_np)\n",
        "    # img_noisy_np = np.log(img_noisy_np/norm)\n",
        "\n",
        "    # val_min = img_noisy_np.min()\n",
        "    # val_range = img_noisy_np.max() - val_min\n",
        "    # img_noisy_np = (img_noisy_np - val_min) / val_range\n",
        "    # img_noisy_np = np.log(img_noisy_np)\n",
        "    # img_noisy_np[img_noisy_np==-np.inf] = 0\n",
        "\n",
        "    \n",
        "\n",
        "    return img_noisy_np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nbconvert\n",
        "!jupyter nbconvert --to html /content/SAR_Despeckling.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv2QYGb5tAio",
        "outputId": "f8e3fbd0-07d1-4463-c8c6-8d1131db5f8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (5.6.1)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert) (5.7.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert) (5.1.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbconvert) (4.11.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert) (2.6.1)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert) (2.11.3)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert) (0.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert) (5.0.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert) (0.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.4->nbconvert) (2.0.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4->nbconvert) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4->nbconvert) (2.16.2)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4->nbconvert) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat>=4.4->nbconvert) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat>=4.4->nbconvert) (4.1.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (5.10.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (22.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert) (1.15.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert) (0.5.1)\n",
            "[NbConvertApp] Converting notebook /content/SAR_Despeckling.ipynb to html\n",
            "[NbConvertApp] Writing 9827415 bytes to /content/SAR_Despeckling.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HS0xFUzIXj3u"
      },
      "outputs": [],
      "source": [
        "# def get_log(img_noisy_np):\n",
        "#   img_noisy_np = np.log(img_noisy_np)\n",
        "#   img_noisy_np[img_noisy_np==-np.inf] = 0\n",
        "#   return img_noisy_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvRtQYd6_8zl"
      },
      "outputs": [],
      "source": [
        "# with ground truth available\n",
        "# img_noisy_pil, img_noisy_np = get_noisy_img(img_np, sigma_)\n",
        "img_noisy_np = generateAddSpeckle(img_np, 20)\n",
        "# img_noisy_np = get_log(img_noisy_np)\n",
        "# img_noisy_np = np.exp(img_noisy_np)\n",
        "print(f'PSNR value: {compare_psnr(img_noisy_np, img_np, data_range=img_noisy_np.max()-img_noisy_np.min())}')\n",
        "img_noisy_pil = np_to_pil(img_noisy_np)\n",
        "plot_image_grid([img_np],4,6)\n",
        "plot_image_grid([img_noisy_np],4,6)\n",
        "(img_np.shape, img_noisy_np.shape)\n",
        "# img_noisy_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8011Au3poaN_"
      },
      "outputs": [],
      "source": [
        "# back = np.exp(img_noisy_np)\n",
        "# val_min = img_noisy_np.min()\n",
        "# val_range = img_noisy_np.max() - val_min\n",
        "# img_noisy_np = (back - val_min) / val_range\n",
        "# plot_image_grid([back],4,6)\n",
        "# ()\n",
        "# img_noisy_np[img_noisy_np==-np.inf]\n",
        "# img_noisy_np.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2v5C5GUQSWn"
      },
      "outputs": [],
      "source": [
        "# np.where(img_noisy_np == 0)\n",
        "# np.where(np.log(img_noisy_np), )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjxguusYDTxS"
      },
      "source": [
        "# Define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6phPZ0N95id"
      },
      "outputs": [],
      "source": [
        "INPUT = 'noise' # 'meshgrid'\n",
        "\n",
        "pad = 'reflection'\n",
        "OPT_OVER = 'net' # 'net,input'\n",
        "\n",
        "reg_noise_std = 1./30. # set to 1./20. for sigma=50\n",
        "# 0.0001 0.001 0.01 0.1\n",
        "LR = 0.01\n",
        "\n",
        "# adam LBFGS \n",
        "OPTIMIZER='adam'\n",
        "# OPTIMIZER='LBFGS'\n",
        "\n",
        "show_every = 100\n",
        "exp_weight=0.99"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T84RTaVc9FBF"
      },
      "outputs": [],
      "source": [
        "# 3000 4000 6000 10000 15000\n",
        "num_iter = 1000\n",
        "# 16 32 48 64\n",
        "input_depth = 32\n",
        "figsize = 4 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSVPrp599Pay",
        "outputId": "cd542f3f-1261-4837-c6ed-5fcf62837aa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside skip\n"
          ]
        }
      ],
      "source": [
        "# returns a model\n",
        "\n",
        "# unet\n",
        "# net = get_net(input_depth, 'UNet', pad,\n",
        "#               skip_n33d=128, \n",
        "#               skip_n33u=128, \n",
        "#               skip_n11=4, \n",
        "#               num_scales=5,\n",
        "#               n_channels=1,\n",
        "#               upsample_mode='bilinear').type(dtype)\n",
        "\n",
        "# resnet\n",
        "# net = ResNet(input_depth, 1, 10, 16, need_sigmoid=True, act_fun='LeakyReLU')\n",
        "# net = net.type(dtype)\n",
        "\n",
        "# texture_nets\n",
        "# net = get_net(input_depth, 'texture_nets', pad,\n",
        "#               skip_n33d=128, \n",
        "#               skip_n33u=128, \n",
        "#               skip_n11=4, \n",
        "#               num_scales=5,\n",
        "#               n_channels=1,\n",
        "#               upsample_mode='bilinear').type(dtype)\n",
        "\n",
        "# net = get_texture_nets(inp=1, conv_num=input_depth, ratios=[32, 16, 8, 4, 2, 1], \n",
        "#                        fill_noise=False, pad=pad).type(dtype)\n",
        "# --------------------------------------\n",
        "# skip\n",
        "net = get_net(input_depth, 'skip', pad,\n",
        "              skip_n33d=128, \n",
        "              skip_n33u=128, \n",
        "              skip_n11=4, \n",
        "              num_scales=5,\n",
        "              n_channels=1,\n",
        "              upsample_mode='bilinear',\n",
        "              act_fun='LeakyReLU').type(dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMomjVWS9RCL",
        "outputId": "ba3cc6d0-3f6c-45ef-ed86-30885e97e01d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 672, 672])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# ./utils/common_utils.py\n",
        "net_input = get_noise(input_depth, INPUT, (img_pil.size[1], img_pil.size[0]), noise_type='n').type(dtype).detach()\n",
        "net_input.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGGgWZKThG_z",
        "outputId": "7121ddbc-b7bf-4593-a356-14992e3c033d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.nn.modules.container.Sequential"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am9Zo0Ly9yQ5",
        "outputId": "26fdf25a-aaf5-4736-a26f-5f0b18729d90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of params: 2217573\n"
          ]
        }
      ],
      "source": [
        "# Compute number of parameters\n",
        "s  = sum([np.prod(list(p.size())) for p in net.parameters()]); \n",
        "print ('Number of params: %d' % s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhrYmtCq-R5W"
      },
      "outputs": [],
      "source": [
        "# Loss\n",
        "mse = torch.nn.MSELoss().type(dtype)\n",
        "# noisy img to torch\n",
        "# img_noisy_torch = np_to_torch(img_noisy_np).type(dtype)\n",
        "\n",
        "# norm = np.linalg.norm(img_noisy_np)\n",
        "# img_noisy_np_norm = img_noisy_np/norm\n",
        "# img_noisy_np = np.log(img_noisy_np)\n",
        "# plot_image_grid([img_noisy_np],4,6)\n",
        "img_noisy_torch = np_to_torch(img_noisy_np).type(dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQTcfRKrvMNC"
      },
      "outputs": [],
      "source": [
        "# img_noisy_torch = torch.log(img_noisy_torch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKkmtN_1_IDt"
      },
      "source": [
        "# Optimize Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrhrH2tg_M-v"
      },
      "outputs": [],
      "source": [
        "net_input_saved = net_input.detach().clone()\n",
        "noise = net_input.detach().clone()\n",
        "out_avg = None\n",
        "last_net = None\n",
        "psrn_noisy_last = 0\n",
        "\n",
        "i = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZGRS99Kf4ge"
      },
      "outputs": [],
      "source": [
        "# if reg_noise_std > 0:\n",
        "#         net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
        "# out = net(net_input)\n",
        "# #  out_np = torch_to_np(out)\n",
        "# out = torch.exp(out)\n",
        "# out_np = torch_to_np(out)\n",
        "# plot_image_grid([out_np],0,1)\n",
        "# total_loss = mse(out, img_noisy_torch)\n",
        "# total_loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9WffyS5_a6a"
      },
      "outputs": [],
      "source": [
        "# Loss funftion printing image\n",
        "lossVal = []\n",
        "def closure():\n",
        "    \n",
        "    global i, out_avg, psrn_noisy_last, last_net, net_input\n",
        "    \n",
        "    # if reg_noise_std > 0:\n",
        "    #     net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
        "        # print(noise.normal_())\n",
        "    net_input = np_to_torch(generateAddSpeckle(torch_to_np(net_input_saved), 20)).type(dtype)\n",
        "    \n",
        "    out = net(net_input)\n",
        "    # out1 = (out.exp() - out.exp().min()) / (out.exp().max()-out.exp().min())\n",
        "    \n",
        "    # Smoothing\n",
        "    if out_avg is None:\n",
        "        out_avg = out.detach()\n",
        "    else:\n",
        "        out_avg = out_avg * exp_weight + out.detach() * (1 - exp_weight)\n",
        "\n",
        "    # print(out.shape, img_noisy_torch.shape)\n",
        "    total_loss = mse(out, img_noisy_torch.exp())\n",
        "    total_loss.backward()\n",
        "        \n",
        "    # print(img_noisy_np.shape, out.detach().cpu().numpy()[0].shape)\n",
        "    # out_npi = out.detach().cpu().numpy()[0], data_range=img_noisy_np.max()-img_noisy_np.min()\n",
        "    # print(test.shape)\n",
        "    psrn_noisy = compare_psnr(img_noisy_np, out.detach().cpu().numpy()[0], data_range=img_noisy_np.max()-img_noisy_np.min()) \n",
        "    psrn_gt    = compare_psnr(img_np, out.detach().cpu().numpy()[0]) \n",
        "    psrn_gt_sm = compare_psnr(img_np, out_avg.detach().cpu().numpy()[0]) \n",
        "    \n",
        "    # So 'PSRN_gt', 'PSNR_gt_sm' only when ground truth is provided\n",
        "    print('Iteration %05d    Loss %f   PSNR_noisy: %f   PSRN_gt: %f PSNR_gt_sm: %f' % (i, total_loss.item(), psrn_noisy, psrn_gt, psrn_gt_sm), end='')\n",
        "\n",
        "    lossVal.append(total_loss.item())\n",
        "    \n",
        "    if  PLOT and i % show_every == 0:\n",
        "        out_np = torch_to_np(out)\n",
        "        # print(out_np)\n",
        "        plot_image_grid([out_np, \n",
        "                         np.clip(torch_to_np(out_avg), 0, 1)], factor=figsize, nrow=1)\n",
        "        # print('Iteration %05d    Loss %f   PSNR_noisy: %f   PSRN_gt: %f PSNR_gt_sm: %f\\n' % (i, total_loss.item(), psrn_noisy, psrn_gt, psrn_gt_sm), end='')         \n",
        "    \n",
        "    # Backtracking\n",
        "    if i % show_every:\n",
        "        if psrn_noisy - psrn_noisy_last < -5: \n",
        "            print('Falling back to previous checkpoint.')\n",
        "\n",
        "            for new_param, net_param in zip(last_net, net.parameters()):\n",
        "                net_param.data.copy_(new_param.cuda())\n",
        "\n",
        "            return total_loss*0\n",
        "        else:\n",
        "            last_net = [x.detach().cpu() for x in net.parameters()]\n",
        "            psrn_noisy_last = psrn_noisy\n",
        "            \n",
        "    i += 1\n",
        "\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mr9Vyh5-_95n"
      },
      "outputs": [],
      "source": [
        "p = get_params(OPT_OVER, net, net_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8hteToVApHT"
      },
      "outputs": [],
      "source": [
        "optimize(OPTIMIZER, p, closure, LR, num_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjcezsK_CF2D"
      },
      "outputs": [],
      "source": [
        "out_np = torch_to_np(net(net_input))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(len(lossVal)),lossVal)\n",
        "plt.title('Loss Function')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "8u8BKEcSsloZ",
        "outputId": "890b9b90-4090-4fdc-cb83-c98452e36dbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tdbO5uwS8O3"
      },
      "outputs": [],
      "source": [
        "exp = np.exp(out_np)\n",
        "val_min = exp.min()\n",
        "val_range = exp.max() - val_min\n",
        "exp = (exp - val_min) / val_range \n",
        "exp = (exp - val_min) / val_range \n",
        "\n",
        "q = plot_image_grid([img_np], factor=13)\n",
        "q = plot_image_grid([exp], factor=13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "Lq4EASknXuj-",
        "outputId": "993de22b-a45d-4c1b-9de5-665318dcc92b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cc4c7f47d4a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompare_psnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_noisy_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_noisy_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mimg_noisy_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'compare_psnr' is not defined"
          ]
        }
      ],
      "source": [
        "compare_psnr(img_noisy_np, out_np, data_range=img_noisy_np.max()-img_noisy_np.min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-5mqm_NYAVj"
      },
      "outputs": [],
      "source": [
        "# compare_psnr(img_np, exp, data_range=exp.max()-exp.min()) \n",
        "# compare_psnr(img_np, out_np) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDAtjMK4xIaR"
      },
      "outputs": [],
      "source": [
        "q = plot_image_grid([exp, img_np], factor=13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72VtTLi1qQEL"
      },
      "outputs": [],
      "source": [
        "# # function for l 1 to 20\n",
        "\n",
        "# L_value = []\n",
        "\n",
        "# before_psnr_noise = []\n",
        "\n",
        "# final_psnr_noise = []\n",
        "# final_psnr_gt = []\n",
        "\n",
        "# for i in range(10,21):\n",
        "#   L_value.append(i)\n",
        "#   print(f'\\nCurrent L value {i}')\n",
        "\n",
        "#   img_noisy_pil, img_noisy_np = generateAddSpeckle(img_np, i)\n",
        "#   plot_image_grid([img_np, img_noisy_np],4,6)\n",
        "  \n",
        "#   before_psnr_noise.append(compare_psnr(img_np,img_noisy_np))\n",
        "\n",
        "#   net_input = get_noise(input_depth, INPUT, (img_pil.size[1], img_pil.size[0]), noise_type='n').type(dtype).detach()\n",
        "\n",
        "#   mse = torch.nn.MSELoss().type(dtype)\n",
        "#   img_noisy_torch = np_to_torch(img_noisy_np).type(dtype)\n",
        "\n",
        "#   net_input_saved = net_input.detach().clone()\n",
        "#   noise = net_input.detach().clone()\n",
        "#   out_avg = None\n",
        "#   last_net = None\n",
        "#   psrn_noisy_last = 0\n",
        "#   i = 0\n",
        "\n",
        "#   p = get_params(OPT_OVER, net, net_input)\n",
        "\n",
        "#   optimize(OPTIMIZER, p, closure, LR, num_iter)\n",
        "\n",
        "#   out_np = torch_to_np(net(net_input))\n",
        "\n",
        "#   final_psnr_noise.append(compare_psnr(img_noisy_np, out_np)) \n",
        "\n",
        "#   final_psnr_gt.append(compare_psnr(img_np, out_np))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fA24hUaozJ7u"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# table = pd.DataFrame({\n",
        "#     'L_value':L_value,\n",
        "#     'before_psnr_noise':before_psnr_noise,\n",
        "#     'final_psnr_noise':final_psnr_noise,\n",
        "#     'final_psnr_gt':final_psnr_gt\n",
        "# }).set_index('L_value')\n",
        "\n",
        "# table\n",
        "# # final_psnr_gt.append(0)\n",
        "# # final_psnr_noise.append(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfq3pKW3OkXM"
      },
      "source": [
        "#----------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwjykEMbxRWz",
        "outputId": "646043f0-2e65-4c1a-d8a1-4b3386d2c3a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(672, 672)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "(img_pil.size[1], img_pil.size[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOht-jbTXsvQ"
      },
      "outputs": [],
      "source": [
        "zero  = torch.zeros([1 ,32 ,544 ,896])\n",
        "var=1./10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VErJNqrjYXEQ"
      },
      "outputs": [],
      "source": [
        "res = zero.normal_()*var\n",
        "res<0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HboVboCqahoU"
      },
      "outputs": [],
      "source": [
        "img_noisy_np.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSzDyPDUzpnY"
      },
      "outputs": [],
      "source": [
        "torch.zeros([4,2,3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymSvjJiqFriN"
      },
      "outputs": [],
      "source": [
        "loc, scale = 0., 1.\n",
        "s = np.random.laplace(loc, scale, [2,5,8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvqV5kBOJTSZ"
      },
      "outputs": [],
      "source": [
        "# np_to_torch(s).shape\n",
        "torch.from_numpy(s).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jXEv0k_KWLj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
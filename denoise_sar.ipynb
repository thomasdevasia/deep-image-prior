{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thomasdevasia/deep-image-prior/blob/master/denoise_sar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NqnrtFZmwJs",
        "outputId": "445d706e-9051-418b-f45f-afeab54c32df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-image-prior'...\n",
            "remote: Enumerating objects: 393, done.\u001b[K\n",
            "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 393 (delta 48), reused 85 (delta 40), pack-reused 289\u001b[K\n",
            "Receiving objects: 100% (393/393), 123.26 MiB | 24.71 MiB/s, done.\n",
            "Resolving deltas: 100% (203/203), done.\n",
            "/content/deep-image-prior\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/thomasdevasia/deep-image-prior\n",
        "# !mv deep-image-prior/* ./\n",
        "%cd deep-image-prior"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "#os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
        "\n",
        "import numpy as np\n",
        "from models import *\n",
        "\n",
        "import torch\n",
        "import torch.optim\n",
        "\n",
        "# from skimage.measure import compare_psnr\n",
        "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
        "from utils.denoising_utils import *\n",
        "\n",
        "import scipy.io as sio\n",
        "\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark =True\n",
        "dtype = torch.cuda.FloatTensor\n",
        "\n",
        "imsize =-1\n",
        "PLOT = True\n",
        "sigma = 25\n",
        "sigma_ = sigma/255."
      ],
      "metadata": {
        "id": "a51yIFT9m-oi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# png SAR image\n",
        "fnamep = 'data/denoising/SAR3.png'\n",
        "# .mat files\n",
        "# fname = 'data/denoising/CL7.mat'\n",
        "fname = 'data/denoising/CL8.mat'\n",
        "# fname = 'data/denoising/CL9.mat'"
      ],
      "metadata": {
        "id": "jWYvpR5anwoL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and prepare Image"
      ],
      "metadata": {
        "id": "rns52qtC6C2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading mat files\n",
        "test = sio.loadmat(fname)\n",
        "intImage = test['x2']\n",
        "temp = pil_to_np(intImage)\n",
        "img_pil = np_to_pil(temp)\n",
        "img_pil = crop_image(img_pil, d=32)\n",
        "# img_np = 255*pil_to_np(img_pil)\n",
        "img_np = pil_to_np(img_pil)\n",
        "# img_np"
      ],
      "metadata": {
        "id": "E_WmPhGR4lfz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_np.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLHpKM8Kq6gG",
        "outputId": "117fc13e-6c91-45f4-a78f-2b05802f5624"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 672, 672)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# img_noisy_pil = crop_image(get_image(fname, imsize)[0], d=32)\n",
        "# img_noisy_np = pil_to_np(img_noisy_pil)\n",
        "\n",
        "# img_pil = img_noisy_pil\n",
        "# img_np = img_noisy_np\n",
        "\n",
        "# plot_image_grid([img_np], 4, 5);"
      ],
      "metadata": {
        "id": "vH2TE-IOpe1E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# im = crop_image(get_image(fname, imsize)[0], d=128)\n",
        "# im.size"
      ],
      "metadata": {
        "id": "qSUzmLAHMlXQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # reading png files\n",
        "# # img_pil = get_image(fname, imsize)[0]\n",
        "# img_pil = crop_image(get_image(fnamep, imsize)[0], d=32)\n",
        "# # converting to numpy\n",
        "# img_np = pil_to_np(img_pil)\n",
        "# # img_np"
      ],
      "metadata": {
        "id": "vLTFtawRq6RL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # # adding speckle noise\n",
        "# def get_noisy_img(img_np, sigma):\n",
        "#   \"\"\"Adds noise to an image.\n",
        "    \n",
        "#   Args: \n",
        "#       img_np: image, np.array with values from 0 to 1\n",
        "#       sigma: std of the noise\n",
        "#   \"\"\"\n",
        "\n",
        "#   np.random.seed(42)\n",
        "\n",
        "#   noise = np.random.normal(loc=1, scale=sigma_, size=img_np.shape)\n",
        "\n",
        "#   # multiplicative noise for speckle noise\n",
        "#   # imgNoise = img_np + (img_np * noise)\n",
        "#   imgNoise = np.log(img_np * noise)\n",
        "\n",
        "#   img_noisy_np = np.clip(abs(imgNoise), 0, 1).astype(np.float32)\n",
        "    \n",
        "#   img_noisy_pil = np_to_pil(img_noisy_np)\n",
        "\n",
        "#   return img_noisy_pil, img_noisy_np"
      ],
      "metadata": {
        "id": "prwA1lGHAcB3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# correct way\n",
        "def generateAddSpeckle(img_np, L):\n",
        "\n",
        "    '''\n",
        "\n",
        "    Creates multiplicative speckled image with number of looks L. L increases lower noise effect, L is lower noise is strong. \n",
        "\n",
        "    '''\n",
        "\n",
        "    sum_ = 0\n",
        "\n",
        "    for i in range(L):\n",
        "\n",
        "        seq1 = np.random.randn(img_np.shape[1], img_np.shape[2])\n",
        "\n",
        "        seq2 = np.random.randn(img_np.shape[1], img_np.shape[2])\n",
        "\n",
        "        temp = np.multiply(seq1, seq1) + np.multiply(seq2, seq2)\n",
        "\n",
        "        sum_ = sum_ + temp/2\n",
        "\n",
        "        #print(i)\n",
        "\n",
        "    speckle_ = np.multiply(sum_,1/L)\n",
        "\n",
        "    img_noisy_np = np.multiply(img_np, speckle_)\n",
        "\n",
        "    img_noisy_np = np.clip(img_noisy_np, 0, 1).astype(np.float32)\n",
        "\n",
        "    img_noisy_pil = np_to_pil(img_noisy_np)\n",
        "\n",
        "    return img_noisy_pil, img_noisy_np"
      ],
      "metadata": {
        "id": "VrEixrIHVOov"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with ground truth available\n",
        "# img_noisy_pil, img_noisy_np = get_noisy_img(img_np, sigma_)\n",
        "img_noisy_pil, img_noisy_np = generateAddSpeckle(img_np, 10)\n",
        "plot_image_grid([img_np, img_noisy_np],4,6)\n",
        "(img_np.shape, img_noisy_np.shape)"
      ],
      "metadata": {
        "id": "kvRtQYd6_8zl"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# when ground truth not available\n",
        "# img_noisy_pil = img_pil\n",
        "# img_noisy_np = img_np"
      ],
      "metadata": {
        "id": "5dzi0fD4nSke"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img_pil\n",
        "# ar = np.array(img_pil)\n",
        "# npImg = ar.transpose(2,0,1).astype(np.float32)/255\n",
        "# img_noisy_np"
      ],
      "metadata": {
        "id": "9kYfmj3SqqNR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# noise = np.random.normal(scale=sigma, size=img_np.shape)\n",
        "# img_noisy_np = np.clip((img_np * noise),0,1).astype(np.float32)\n",
        "# img_noisy_pil = np_to_pil(img_noisy_np)\n",
        "# img_noisy_np\n",
        "\n",
        "# plot_image_grid\n",
        "# plot_image_grid([img_noisy_np],4,6)\n",
        "# img_pil"
      ],
      "metadata": {
        "id": "CeHoCjqUCeVX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # from torch.cuda.random import seed\n",
        "# # checking for the noise to add\n",
        "# # np.log(img_np * noise)\n",
        "# # img_np\n",
        "# np.random.seed(42)\n",
        "# # noise = np.random.normal(scale=sigma_, size=img_np.shape)\n",
        "# noise = np.random.uniform(0, 1, img_np.shape)\n",
        "\n",
        "# print(img_np.shape, noise.shape)\n",
        "# # imgNoise = img_np + noise\n",
        "# imgNoise = np.log(img_np + noise)\n",
        "# # imgNoise = img_np + (img_np * noise)\n",
        "# res = np.clip(imgNoise, 0, 1).astype(np.float32)\n",
        "# plot_image_grid([res],4,6)"
      ],
      "metadata": {
        "id": "VI0AhHfphTih"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # add noise\n",
        "# img_noisy_np = get_noisy_img(img_np, sigma_)"
      ],
      "metadata": {
        "id": "4g1jw7w4y0UJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot_image_grid([img_np, img_noisy_np], 4, 6);\n",
        "# n_channels = max(x.shape[0] for x in [img_np, img_noisy_np])\n",
        "# img_noisy_np.shape"
      ],
      "metadata": {
        "id": "njrkItR4y-AC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define model"
      ],
      "metadata": {
        "id": "CjxguusYDTxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT = 'noise' # 'meshgrid'\n",
        "pad = 'reflection'\n",
        "OPT_OVER = 'net' # 'net,input'\n",
        "\n",
        "reg_noise_std = 1./30. # set to 1./20. for sigma=50\n",
        "# 0.0001 0.001 0.01 0.1\n",
        "LR = 0.01\n",
        "\n",
        "OPTIMIZER='adam' # 'LBFGS'\n",
        "# OPTIMIZER='LBFGS'\n",
        "show_every = 100\n",
        "exp_weight=0.99"
      ],
      "metadata": {
        "id": "X6phPZ0N95id"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3000 4000 6000 10000 15000\n",
        "num_iter = 2000\n",
        "input_depth = 32 \n",
        "figsize = 4 "
      ],
      "metadata": {
        "id": "T84RTaVc9FBF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# returns a model\n",
        "# net = get_net(input_depth, 'UNet', pad,\n",
        "#               skip_n33d=128, \n",
        "#               skip_n33u=128, \n",
        "#               skip_n11=4, \n",
        "#               num_scales=5,\n",
        "              # upsample_mode='bilinear').type(dtype)\n",
        "net = get_net(input_depth, 'skip', pad,\n",
        "              skip_n33d=128, \n",
        "              skip_n33u=128, \n",
        "              skip_n11=4, \n",
        "              num_scales=5,\n",
        "              n_channels=1,\n",
        "              upsample_mode='bilinear').type(dtype)"
      ],
      "metadata": {
        "id": "HSVPrp599Pay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fffbb075-e7ec-4026-fba2-582704a4ac79"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside skip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ./utils/common_utils.py\n",
        "net_input = get_noise(input_depth, INPUT, (img_pil.size[1], img_pil.size[0]), noise_type='n').type(dtype).detach()\n",
        "net_input.shape"
      ],
      "metadata": {
        "id": "IMomjVWS9RCL",
        "outputId": "54c60b37-3d8a-43fe-d3a0-89b3013c5e19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 672, 672])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute number of parameters\n",
        "s  = sum([np.prod(list(p.size())) for p in net.parameters()]); \n",
        "print ('Number of params: %d' % s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am9Zo0Ly9yQ5",
        "outputId": "724d2706-a8f6-460f-dfa2-e3574a507e20"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of params: 2217573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss\n",
        "mse = torch.nn.MSELoss().type(dtype)\n",
        "# noise to change and see\n",
        "img_noisy_torch = np_to_torch(img_noisy_np).type(dtype)"
      ],
      "metadata": {
        "id": "mhrYmtCq-R5W"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimize Model"
      ],
      "metadata": {
        "id": "GKkmtN_1_IDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net_input_saved = net_input.detach().clone()\n",
        "noise = net_input.detach().clone()\n",
        "out_avg = None\n",
        "last_net = None\n",
        "psrn_noisy_last = 0\n",
        "\n",
        "i = 0"
      ],
      "metadata": {
        "id": "ZrhrH2tg_M-v"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss funftion printing image\n",
        "def closure():\n",
        "    \n",
        "    global i, out_avg, psrn_noisy_last, last_net, net_input\n",
        "    \n",
        "    if reg_noise_std > 0:\n",
        "        net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
        "    \n",
        "    out = net(net_input)\n",
        "    \n",
        "    # Smoothing\n",
        "    if out_avg is None:\n",
        "        out_avg = out.detach()\n",
        "    else:\n",
        "        out_avg = out_avg * exp_weight + out.detach() * (1 - exp_weight)\n",
        "            \n",
        "    total_loss = mse(out, img_noisy_torch)\n",
        "    total_loss.backward()\n",
        "        \n",
        "    # print(img_noisy_np.shape, out.detach().cpu().numpy()[0].shape)\n",
        "    psrn_noisy = compare_psnr(img_noisy_np, out.detach().cpu().numpy()[0]) \n",
        "    psrn_gt    = compare_psnr(img_np, out.detach().cpu().numpy()[0]) \n",
        "    psrn_gt_sm = compare_psnr(img_np, out_avg.detach().cpu().numpy()[0]) \n",
        "    \n",
        "    # So 'PSRN_gt', 'PSNR_gt_sm' only when ground truth is provided\n",
        "    print('Iteration %05d    Loss %f   PSNR_noisy: %f   PSRN_gt: %f PSNR_gt_sm: %f' % (i, total_loss.item(), psrn_noisy, psrn_gt, psrn_gt_sm), end='')\n",
        "\n",
        "    if  PLOT and i % show_every == 0:\n",
        "        out_np = torch_to_np(out)\n",
        "        plot_image_grid([np.clip(out_np, 0, 1), \n",
        "                         np.clip(torch_to_np(out_avg), 0, 1)], factor=figsize, nrow=1)\n",
        "        \n",
        "         \n",
        "    \n",
        "    # Backtracking\n",
        "    if i % show_every:\n",
        "        if psrn_noisy - psrn_noisy_last < -5: \n",
        "            print('Falling back to previous checkpoint.')\n",
        "\n",
        "            for new_param, net_param in zip(last_net, net.parameters()):\n",
        "                net_param.data.copy_(new_param.cuda())\n",
        "\n",
        "            return total_loss*0\n",
        "        else:\n",
        "            last_net = [x.detach().cpu() for x in net.parameters()]\n",
        "            psrn_noisy_last = psrn_noisy\n",
        "            \n",
        "    i += 1\n",
        "\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "O9WffyS5_a6a"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = get_params(OPT_OVER, net, net_input)"
      ],
      "metadata": {
        "id": "mr9Vyh5-_95n"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimize(OPTIMIZER, p, closure, LR, num_iter)"
      ],
      "metadata": {
        "id": "_8hteToVApHT"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_np = torch_to_np(net(net_input))"
      ],
      "metadata": {
        "id": "fjcezsK_CF2D"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = plot_image_grid([np.clip(out_np, 0, 1), img_np], factor=13);"
      ],
      "metadata": {
        "id": "eDAtjMK4xIaR"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#----------------------"
      ],
      "metadata": {
        "id": "yfq3pKW3OkXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(img_pil.size[1], img_pil.size[0])"
      ],
      "metadata": {
        "id": "DwjykEMbxRWz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d6463d6-1a2f-4828-cd95-98c112dd9282"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(672, 672)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zero  = torch.zeros([1 ,32 ,544 ,896])\n",
        "var=1./10"
      ],
      "metadata": {
        "id": "kOht-jbTXsvQ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = zero.normal_()*var\n",
        "res<0"
      ],
      "metadata": {
        "id": "VErJNqrjYXEQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0af9cc1c-bb41-4ac7-9386-1c0bcaf6e083"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ True,  True, False,  ...,  True, False, False],\n",
              "          [ True, False, False,  ...,  True,  True, False],\n",
              "          [ True,  True, False,  ...,  True, False, False],\n",
              "          ...,\n",
              "          [False, False, False,  ...,  True,  True, False],\n",
              "          [ True, False,  True,  ...,  True,  True,  True],\n",
              "          [False,  True, False,  ...,  True, False, False]],\n",
              "\n",
              "         [[ True, False,  True,  ..., False, False,  True],\n",
              "          [False, False, False,  ...,  True,  True, False],\n",
              "          [ True, False,  True,  ...,  True, False,  True],\n",
              "          ...,\n",
              "          [False,  True,  True,  ..., False, False, False],\n",
              "          [False, False, False,  ..., False, False,  True],\n",
              "          [False,  True,  True,  ...,  True, False,  True]],\n",
              "\n",
              "         [[False, False, False,  ...,  True, False, False],\n",
              "          [False, False,  True,  ..., False,  True, False],\n",
              "          [False,  True, False,  ...,  True, False, False],\n",
              "          ...,\n",
              "          [ True, False, False,  ..., False,  True, False],\n",
              "          [ True,  True, False,  ...,  True, False, False],\n",
              "          [False, False,  True,  ...,  True, False, False]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ True, False,  True,  ..., False,  True,  True],\n",
              "          [False,  True,  True,  ..., False, False, False],\n",
              "          [False,  True, False,  ..., False,  True,  True],\n",
              "          ...,\n",
              "          [ True,  True, False,  ...,  True,  True,  True],\n",
              "          [False,  True, False,  ..., False, False,  True],\n",
              "          [False, False,  True,  ...,  True,  True, False]],\n",
              "\n",
              "         [[ True, False,  True,  ..., False, False, False],\n",
              "          [ True,  True,  True,  ...,  True, False, False],\n",
              "          [False,  True,  True,  ..., False,  True, False],\n",
              "          ...,\n",
              "          [False, False, False,  ...,  True,  True, False],\n",
              "          [ True, False, False,  ...,  True, False,  True],\n",
              "          [False, False, False,  ...,  True, False, False]],\n",
              "\n",
              "         [[ True,  True,  True,  ..., False,  True, False],\n",
              "          [ True, False,  True,  ...,  True, False, False],\n",
              "          [False, False,  True,  ...,  True,  True, False],\n",
              "          ...,\n",
              "          [False, False, False,  ...,  True, False, False],\n",
              "          [ True,  True, False,  ...,  True,  True, False],\n",
              "          [ True,  True,  True,  ..., False,  True,  True]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_noisy_np.shape"
      ],
      "metadata": {
        "id": "HboVboCqahoU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a92c1c68-21ab-4c91-ffea-f1c48a9f9280"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 672, 672)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros([4,2,3])"
      ],
      "metadata": {
        "id": "WSzDyPDUzpnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbeda0dc-9cd8-4bf4-a6cc-9f9e10f4774d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0.],\n",
              "         [0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.],\n",
              "         [0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.],\n",
              "         [0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.],\n",
              "         [0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loc, scale = 0., 1.\n",
        "s = np.random.laplace(loc, scale, [2,5,8])"
      ],
      "metadata": {
        "id": "ymSvjJiqFriN"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np_to_torch(s).shape\n",
        "torch.from_numpy(s).shape"
      ],
      "metadata": {
        "id": "AvqV5kBOJTSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "119ef03d-3d97-4f30-abd6-b15cd3d272dd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 5, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4jXEv0k_KWLj"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}